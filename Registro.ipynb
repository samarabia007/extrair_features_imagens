{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Alinhamento de imagens, que foram obtidas por diferentes técnicas de imageamento, por pontos-chaves (ORB).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import cv2 as cv\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n\n# ler duas imagens\nimg1 = cv.imread('uv20161004rosael-8_reduzida_para_257.jpg', cv.IMREAD_GRAYSCALE)\nimg2 = cv.imread('quiteriaIR_reduzida_para_257.jpg', cv.IMREAD_GRAYSCALE)\n\n# Dar o ORB nelas\norb = cv.ORB_create()\nkp1, des1 = orb.detectAndCompute(img1, None)\nkp2, des2 = orb.detectAndCompute(img2, None)\n\n# Dar o Brute Force Matcher e os descriptors bf.Match(des1, des2)\nbf = cv.BFMatcher (cv.NORM_HAMMING, crossCheck = True)\nmatches = bf.match(des1, des2)\n\n# Ordena-os por distância\nmatches = sorted(matches, key = lambda x:x.distance)\n\n# Cria variáveis com uma das dimensões do tamanho do número de matches \nmatches = matches[:int(len(matches)*90)]\nno_of_matches = len(matches)\np1 = np.zeros((no_of_matches, 2))\np2 = np.zeros((no_of_matches, 2))\n\n# Atribui o queryIdx dos kp1 dos matches da img1 à variável p1 e os trainIdx da img2 (à variável p2)\nfor i in range(len(matches)):\n    p1[i, :] = kp1[matches[i].queryIdx].pt\n    p2[i, :] = kp2[matches[i].trainIdx].pt\n    \n# Cria máscara, homografia e imagem transformada por elas\nhomography, mask = cv.findHomography(p1, p2, cv.RANSAC)\ntransformed_img = cv.warpPerspective(img1, homography, (706,705))\ncv.imwrite('imagem_transformada.jpg', transformed_img)\n                                     \n# Desenha os 10 primeiros matches\nimg3 = cv.drawMatches(img1,kp1,img2,kp2,matches[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\nplt.imshow(img3),plt.show()\nimg3 = Image.fromarray(img3)\nimg3.save('img3.png', format = 'PNG')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Após alinhadas as imagens, sabemos que os pixelsets de uma correspondem à mesma região de pintura dos pixelsets da outra. Assim, podemos extrair informações de cada pixelset das duas imagens e tratá-las conjuntamente.",
      "metadata": {}
    }
  ]
}
